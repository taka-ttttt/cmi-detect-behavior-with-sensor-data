{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ae90458",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:18:16.533323Z",
     "iopub.status.busy": "2025-07-15T11:18:16.532506Z",
     "iopub.status.idle": "2025-07-15T11:18:25.229394Z",
     "shell.execute_reply": "2025-07-15T11:18:25.228551Z"
    },
    "papermill": {
     "duration": 8.701222,
     "end_time": "2025-07-15T11:18:25.230887",
     "exception": false,
     "start_time": "2025-07-15T11:18:16.529665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib\n",
    "import warnings\n",
    "import random\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import find_peaks\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92a5ee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-15T11:18:25.235579Z",
     "iopub.status.busy": "2025-07-15T11:18:25.235130Z",
     "iopub.status.idle": "2025-07-15T11:18:29.466123Z",
     "shell.execute_reply": "2025-07-15T11:18:29.465446Z"
    },
    "papermill": {
     "duration": 4.234819,
     "end_time": "2025-07-15T11:18:29.467418",
     "exception": false,
     "start_time": "2025-07-15T11:18:25.232599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "TRAIN = True  # Set to True to train and save models, False for inference\n",
    "MODEL_DIR = \"model\"\n",
    "BASE_PATH = \"input/\"\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bb4d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---  Feature Engineering ---\n",
    "def feature_set(df: pd.DataFrame, use_extra: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts an enhanced set of features from sensor data for gesture prediction.\n",
    "\n",
    "    Features include:\n",
    "    - Basic statistics (mean, std, min, max, median)\n",
    "    - Advanced statistics (energy, range, quantiles, skew, kurtosis)\n",
    "    - Peak detection for IMU signals\n",
    "    - Frequency band energy from FFT\n",
    "    - Aggregated thermal and ToF features (max/std, rate of change)\n",
    "    \"\"\"\n",
    "    feats = {}\n",
    "    imu_cols = [c for c in df.columns if any(x in c for x in ['acc_', 'rot_'])]\n",
    "\n",
    "    # Vector magnitudes and jerk features\n",
    "    df['acc_mag'] = np.sqrt(df['acc_x']**2 + df['acc_y']**2 + df['acc_z']**2)\n",
    "    df['rot_mag'] = np.sqrt(df['rot_x']**2 + df['rot_y']**2 + df['rot_z']**2)\n",
    "    df['acc_jerk_x'] = df['acc_x'].diff().fillna(0)\n",
    "    df['acc_jerk_y'] = df['acc_y'].diff().fillna(0)\n",
    "    df['acc_jerk_z'] = df['acc_z'].diff().fillna(0)\n",
    "    imu_cols.extend(['acc_mag', 'rot_mag', 'acc_jerk_x', 'acc_jerk_y', 'acc_jerk_z'])\n",
    "\n",
    "    # Feature Extraction for IMU Sensors\n",
    "    for col in imu_cols:\n",
    "        arr = df[col].values\n",
    "        # Basic Statistics\n",
    "        feats[f'{col}_mean'] = np.mean(arr)\n",
    "        feats[f'{col}_std'] = np.std(arr)\n",
    "        feats[f'{col}_min'] = np.min(arr)\n",
    "        feats[f'{col}_max'] = np.max(arr)\n",
    "        feats[f'{col}_median'] = np.median(arr)\n",
    "        feats[f'{col}_range'] = feats[f'{col}_max'] - feats[f'{col}_min']\n",
    "        # Advanced Statistics\n",
    "        feats[f'{col}_q25'] = np.quantile(arr, 0.25)\n",
    "        feats[f'{col}_q75'] = np.quantile(arr, 0.75)\n",
    "        feats[f'{col}_energy'] = np.sum(arr**2) / len(arr)\n",
    "        feats[f'{col}_skew'] = skew(arr)\n",
    "        feats[f'{col}_kurtosis'] = kurtosis(arr)\n",
    "        # Rolling Window Features\n",
    "        for window in [5, 10, 15, 20, 25, 50]:\n",
    "            rolling_mean = df[col].rolling(window=window, min_periods=1).mean()\n",
    "            rolling_std = df[col].rolling(window=window, min_periods=1).std().fillna(0)\n",
    "            feats[f'{col}_roll_mean_{window}_mean'] = rolling_mean.mean()\n",
    "            feats[f'{col}_roll_std_{window}_mean'] = rolling_std.mean()\n",
    "        # Frequency Domain Features (FFT)\n",
    "        fft_vals = rfft(arr)\n",
    "        fft_mags = np.abs(fft_vals)\n",
    "        if len(fft_mags) > 1:\n",
    "            feats[f'{col}_fft_mean'] = np.mean(fft_mags)\n",
    "            feats[f'{col}_fft_max'] = np.max(fft_mags)\n",
    "            freqs = rfftfreq(len(arr))\n",
    "            feats[f'{col}_fft_dominant_freq'] = freqs[np.argmax(fft_mags[1:]) + 1] if len(fft_mags) > 1 else 0\n",
    "            # Energy in Frequency Bands\n",
    "            bands = [(0, 2), (2, 5), (5, 10)]\n",
    "            for low, high in bands:\n",
    "                mask = (freqs >= low) & (freqs < high)\n",
    "                feats[f'{col}_fft_energy_{low}_{high}'] = np.sum(fft_mags[mask])\n",
    "        # Peak Detection\n",
    "        peaks, _ = find_peaks(arr, height=0)\n",
    "        feats[f'{col}_num_peaks'] = len(peaks) / len(arr)\n",
    "\n",
    "    # Cross-Sensor Correlations\n",
    "    for (c1, c2) in [('acc_x', 'acc_y'), ('acc_x', 'acc_z'), ('acc_y', 'acc_z'),\n",
    "                     ('rot_x', 'rot_y'), ('rot_x', 'rot_z'), ('rot_y', 'rot_z')]:\n",
    "        if c1 in df.columns and c2 in df.columns:\n",
    "            feats[f'{c1}_{c2}_corr'] = np.corrcoef(df[c1], df[c2])[0, 1]\n",
    "\n",
    "    # Extra Sensor Features (Thermal & ToF)\n",
    "    if use_extra:\n",
    "        thm_cols = [c for c in df.columns if 'thm' in c]\n",
    "        tof_cols = [c for c in df.columns if 'tof' in c]\n",
    "        # Thermal Features\n",
    "        if thm_cols:\n",
    "            thm_data = df[thm_cols].values\n",
    "            feats['thm_max_across_sensors'] = np.nanmax(thm_data, axis=1).mean()\n",
    "            feats['thm_std_across_sensors'] = np.nanstd(thm_data, axis=1).mean()\n",
    "            for col in thm_cols:\n",
    "                feats[f'{col}_mean'] = np.nanmean(df[col])\n",
    "                feats[f'{col}_max'] = np.nanmax(df[col])\n",
    "                feats[f'{col}_diff_mean'] = df[col].diff().abs().mean()\n",
    "        # ToF Features\n",
    "        if tof_cols:\n",
    "            tof_data = df[tof_cols].values\n",
    "            valid_tof = tof_data >= 0\n",
    "            min_tof_per_time = np.min(tof_data, axis=1, where=valid_tof, initial=10000)\n",
    "            feats['tof_min_across_sensors'] = np.mean(min_tof_per_time)\n",
    "            feats['tof_num_valid_sensors'] = np.sum(valid_tof, axis=1).mean()\n",
    "            for col in tof_cols:\n",
    "                valid_vals = df[col][df[col] >= 0]\n",
    "                if valid_vals.size > 0:\n",
    "                    feats[f'{col}_mean'] = np.mean(valid_vals)\n",
    "                    feats[f'{col}_min'] = np.min(valid_vals)\n",
    "                    feats[f'{col}_diff_mean'] = df[col].diff().abs().mean()\n",
    "\n",
    "    return feats\n",
    "\n",
    "def build_features(data: pd.DataFrame, demographics: pd.DataFrame, use_extra: bool) -> tuple[pd.DataFrame, list]:\n",
    "    \"\"\"Builds feature matrix and returns features with subject groups for CV.\"\"\"\n",
    "    features = []\n",
    "    groups = []\n",
    "    for seq_id, g in data.groupby('sequence_id'):\n",
    "        subj = g['subject'].iloc[0]\n",
    "        groups.append(subj)\n",
    "        feats = feature_set(g, use_extra=use_extra)\n",
    "        feats['sequence_id'] = seq_id\n",
    "        demo_row = demographics[demographics['subject'] == subj]\n",
    "        if not demo_row.empty:\n",
    "            demo = demo_row.iloc[0]\n",
    "            for dcol in ['age', 'sex', 'height_cm', 'handedness']:\n",
    "                feats[dcol] = demo.get(dcol, np.nan)\n",
    "        features.append(feats)\n",
    "    df_feats = pd.DataFrame(features).set_index('sequence_id')\n",
    "    if 'sex' in df_feats.columns:\n",
    "        df_feats['sex'] = df_feats['sex'].map({'M': 1, 'F': 0})\n",
    "    if 'handedness' in df_feats.columns:\n",
    "        df_feats['handedness'] = df_feats['handedness'].map({'R': 1, 'L': 0, 'A': 2})\n",
    "    return df_feats, groups\n",
    "\n",
    "# --- Training Pipeline ---\n",
    "def train_cv(X: pd.DataFrame, y: pd.Series, groups: list, name: str = \"model\"):\n",
    "    \"\"\"Trains a LightGBM model with GroupKFold CV.\"\"\"\n",
    "    print(f\"\\n--- Training {name} model ---\")\n",
    "    print(f\"Training with {X.shape[0]} sequences and {X.shape[1]} features.\")\n",
    "    val_scores = []\n",
    "    lgbm_params = {\n",
    "        'objective': 'multiclass', 'metric': 'multi_logloss',\n",
    "        'n_estimators': 3000, 'learning_rate': 0.015,\n",
    "        'feature_fraction': 0.7, 'bagging_fraction': 0.7,\n",
    "        'bagging_freq': 1, 'lambda_l1': 0.3, 'lambda_l2': 0.3,\n",
    "        'num_leaves': 60, 'min_child_samples': 20,\n",
    "        'n_jobs': -1, 'seed': 42, 'boosting_type': 'gbdt', 'verbose': -1\n",
    "    }\n",
    "    for fold, (tr_idx, val_idx) in enumerate(GroupKFold(n_splits=5).split(X, y, groups)):\n",
    "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "        model = lgb.LGBMClassifier(**lgbm_params)\n",
    "        model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)],\n",
    "                  eval_metric='multi_logloss',\n",
    "                  callbacks=[lgb.early_stopping(150, verbose=False)])\n",
    "        preds = model.predict(X_val)\n",
    "        f1 = f1_score(y_val, preds, average='macro')\n",
    "        val_scores.append(f1)\n",
    "        print(f\"Fold {fold} F1-Macro: {f1:.4f}\")\n",
    "    print(f\"Mean CV F1-Macro: {np.mean(val_scores):.4f}\")\n",
    "    model = lgb.LGBMClassifier(**lgbm_params)\n",
    "    model.fit(X, y)\n",
    "    joblib.dump(model, os.path.join(MODEL_DIR, f\"model_{name}.pkl\"))\n",
    "    print(f\"Saved {name} model to {MODEL_DIR}/model_{name}.pkl\")\n",
    "    return model\n",
    "\n",
    "def train_pipeline():\n",
    "    \"\"\"Executes the training pipeline for IMU-only and full-sensor models.\"\"\"\n",
    "    print(\"===== Starting Training Pipeline =====\")\n",
    "    print(\"Loading Data...\")\n",
    "    train = pd.read_csv(BASE_PATH + \"train.csv\")\n",
    "    train_d = pd.read_csv(BASE_PATH + \"train_demographics.csv\")\n",
    "    train = train.groupby(\"sequence_id\").apply(lambda g: g.ffill().bfill()).reset_index(drop=True)\n",
    "    print(\"Encoding...\")\n",
    "    le_gesture = LabelEncoder()\n",
    "    train[\"e_gesture\"] = le_gesture.fit_transform(train[\"gesture\"])\n",
    "    all_seq_ids = train['sequence_id'].unique()\n",
    "    imu_only_seq_ids = np.random.choice(all_seq_ids, size=int(0.5 * len(all_seq_ids)), replace=False)\n",
    "    extra_seq_ids = [sid for sid in all_seq_ids if sid not in imu_only_seq_ids]\n",
    "    print(f\"Created {len(imu_only_seq_ids)} IMU-only and {len(extra_seq_ids)} full-sensor sequences.\")\n",
    "\n",
    "    print(\"Building features for IMU-only model...\")\n",
    "    X_imu, groups_imu = build_features(train[train['sequence_id'].isin(imu_only_seq_ids)], train_d, use_extra=False)\n",
    "    y_imu = train.groupby('sequence_id')['e_gesture'].first().loc[X_imu.index]\n",
    "    print(\"Building features for full-sensor model...\")\n",
    "    X_extra, groups_extra = build_features(train[train['sequence_id'].isin(extra_seq_ids)], train_d, use_extra=True)\n",
    "    y_extra = train.groupby('sequence_id')['e_gesture'].first().loc[X_extra.index]\n",
    "\n",
    "    imu_cols = X_imu.columns\n",
    "    extra_cols = X_extra.columns\n",
    "    X_imu = X_imu[imu_cols].copy()\n",
    "    X_extra = X_extra[extra_cols].copy()  # Use all extra columns\n",
    "\n",
    "    model_imu = train_cv(X_imu, y_imu, groups_imu, \"imu\")\n",
    "    model_extra = train_cv(X_extra, y_extra, groups_extra, \"extra\")\n",
    "    joblib.dump(le_gesture, os.path.join(MODEL_DIR, \"le_gesture.pkl\"))\n",
    "    print(\"Saved label encoder to le_gesture.pkl\")\n",
    "    print(\"===== Training Pipeline Complete =====\")\n",
    "\n",
    "# --- Inference Pipeline ---\n",
    "def has_extra_sensors(df: pd.DataFrame) -> bool:\n",
    "    \"\"\"Checks if a sequence has valid thermal/ToF sensor data.\"\"\"\n",
    "    thm_cols = [c for c in df.columns if 'thm_' in c]\n",
    "    tof_cols = [c for c in df.columns if 'tof_' in c]\n",
    "    if not thm_cols or not tof_cols:\n",
    "        return False\n",
    "    has_thm = df[thm_cols].notna().any().any()\n",
    "    has_tof = (df[tof_cols] != -1).any().any()\n",
    "    return has_thm and has_tof\n",
    "\n",
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    \"\"\"Predicts the gesture for a single sequence.\"\"\"\n",
    "    sequence_pd = sequence.to_pandas()\n",
    "    demographics_pd = demographics.to_pandas()\n",
    "    try:\n",
    "        model_imu = joblib.load(os.path.join(MODEL_DIR, \"model_imu.pkl\"))\n",
    "        model_extra = joblib.load(os.path.join(MODEL_DIR, \"model_extra.pkl\"))\n",
    "        le_gesture = joblib.load(os.path.join(MODEL_DIR, \"le_gesture.pkl\"))\n",
    "        use_extra = has_extra_sensors(sequence_pd)\n",
    "        df_feats, _ = build_features(sequence_pd.assign(sequence_id=0), demographics_pd, use_extra)\n",
    "        model = model_extra if use_extra else model_imu\n",
    "        model_cols = model.feature_name_\n",
    "        df_feats = df_feats.reindex(columns=model_cols, fill_value=0)\n",
    "        pred = model.predict(df_feats)[0]\n",
    "        return le_gesture.inverse_transform([pred])[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error: {e}\")\n",
    "        le_gesture = joblib.load(os.path.join(MODEL_DIR, \"le_gesture.pkl\"))\n",
    "        return le_gesture.classes_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f014cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Starting Training Pipeline =====\n",
      "Loading Data...\n",
      "Encoding...\n",
      "Created 4075 IMU-only and 4076 full-sensor sequences.\n",
      "Building features for IMU-only model...\n",
      "Building features for full-sensor model...\n",
      "\n",
      "--- Training imu model ---\n",
      "Training with 4075 sequences and 370 features.\n",
      "Fold 0 F1-Macro: 0.5758\n",
      "Fold 1 F1-Macro: 0.5630\n",
      "Fold 2 F1-Macro: 0.5816\n",
      "Fold 3 F1-Macro: 0.5536\n",
      "Fold 4 F1-Macro: 0.5563\n",
      "Mean CV F1-Macro: 0.5660\n",
      "Saved imu model to model/model_imu.pkl\n",
      "\n",
      "--- Training extra model ---\n",
      "Training with 4076 sequences and 1349 features.\n",
      "Fold 0 F1-Macro: 0.5403\n",
      "Fold 1 F1-Macro: 0.6147\n",
      "Fold 2 F1-Macro: 0.6419\n",
      "Fold 3 F1-Macro: 0.6456\n",
      "Fold 4 F1-Macro: 0.6177\n",
      "Mean CV F1-Macro: 0.6120\n",
      "Saved extra model to model/model_extra.pkl\n",
      "Saved label encoder to le_gesture.pkl\n",
      "===== Training Pipeline Complete =====\n"
     ]
    }
   ],
   "source": [
    "# --- Main Execution Block ---\n",
    "if __name__ == \"__main__\":\n",
    "    if TRAIN:\n",
    "        os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "        train_pipeline()\n",
    "    else:\n",
    "        print(\"===== Inference Mode =====\")\n",
    "        print(f\"Models will be loaded from '{MODEL_DIR}'.\")\n",
    "        # Kaggle Inference Server Setup\n",
    "        try:\n",
    "            import kaggle_evaluation.cmi_inference_server\n",
    "            inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "            if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "                inference_server.serve()\n",
    "                print(\"Inference server started for submission.\")\n",
    "            else:\n",
    "                print(\"Starting local inference gateway for testing...\")\n",
    "                inference_server.run_local_gateway(\n",
    "                    data_paths=(\n",
    "                        os.path.join(BASE_PATH, 'test.csv'),\n",
    "                        os.path.join(BASE_PATH, 'test_demographics.csv'),\n",
    "                    )\n",
    "                )\n",
    "        except (ImportError, ModuleNotFoundError):\n",
    "            print(\"Kaggle evaluation module not found. Skipping inference server setup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43428f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "datasetId": 7818518,
     "sourceId": 12473004,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.454362,
   "end_time": "2025-07-15T11:18:30.286462",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-15T11:18:11.832100",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
